[2025-07-18 01:31:31,802][lightning_fabric.utilities.seed][INFO] - [rank: 0] Global seed set to 0
[2025-07-18 01:31:31,812][torch.distributed.nn.jit.instantiator][INFO] - Created a temporary directory at /tmp/tmpggwvwm6o
[2025-07-18 01:31:31,813][torch.distributed.nn.jit.instantiator][INFO] - Writing /tmp/tmpggwvwm6o/_remote_module_non_sriptable.py
[2025-07-18 01:31:37,723][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True
[2025-07-18 01:31:37,724][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2025-07-18 01:31:37,724][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2025-07-18 01:31:37,724][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2025-07-18 01:31:37,724][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..
[2025-07-18 01:31:37,724][pytorch_lightning.utilities.rank_zero][INFO] - `Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
[2025-07-18 01:31:37,747][lightning_fabric.utilities.seed][INFO] - [rank: 0] Global seed set to 0
[2025-07-18 01:31:37,749][lightning_fabric.utilities.distributed][INFO] - Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
